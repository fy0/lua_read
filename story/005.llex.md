
# llex.h

是时候进入词法分析器部分了。

按照惯例，先看头文件。

## 1

这个文件引用了 lobject.h 和 lzio.h

我不太清楚 ZIO 指的是什么，但应该是某种封装好的IO对象。

```C
#define FIRST_RESERVED	257
```

这是什么？保留字的数量上限？

```C

/*
* WARNING: if you change the order of this enumeration,
* grep "ORDER RESERVED"
*/
enum RESERVED {
  /* terminal symbols denoted by reserved words */
  TK_AND = FIRST_RESERVED, TK_BREAK,
  TK_DO, TK_ELSE, TK_ELSEIF, TK_END, TK_FALSE, TK_FOR, TK_FUNCTION,
  TK_GOTO, TK_IF, TK_IN, TK_LOCAL, TK_NIL, TK_NOT, TK_OR, TK_REPEAT,
  TK_RETURN, TK_THEN, TK_TRUE, TK_UNTIL, TK_WHILE,
  /* other terminal symbols */
  TK_IDIV, TK_CONCAT, TK_DOTS, TK_EQ, TK_GE, TK_LE, TK_NE,
  TK_SHL, TK_SHR,
  TK_DBCOLON, TK_EOS,
  TK_FLT, TK_INT, TK_NAME, TK_STRING
};

/* number of reserved words */
#define NUM_RESERVED	(cast(int, TK_WHILE-FIRST_RESERVED+1))
```

哦 并非如此，是第一个保留字的值，为什么要选择257呢？

十六进制的FF是255，那么257的十六进制是101，若没记错内存中会是01 01，然后是02 01，03 01 ...

=====

补充：过了两天我又看这个 token 列表的时候，发现了奇怪之处。

这个 token 列表的内容是如此之少，加减乘除去哪了？

于是我明白了 > 256 的意图。

## 2

```C
typedef union {
  lua_Number r;
  lua_Integer i;
  TString *ts;
} SemInfo;  /* semantics information */


typedef struct Token {
  int token;
  SemInfo seminfo;
} Token;
```

语义信息以及 token

lua_Number 是个 double 类型而 lua_Integer 是 int

我觉得可能大部分 token 都是 TString，因为union中另外两种的类型能包含的信息真的是太少了。


```C
/* state of the lexer plus state of the parser when shared by all
   functions */
typedef struct LexState {
  int current;  /* current character (charint) */
  int linenumber;  /* input line counter */
  int lastline;  /* line of last token 'consumed' */
  Token t;  /* current token */
  Token lookahead;  /* look ahead token */
  struct FuncState *fs;  /* current function (parser) */
  struct lua_State *L;
  ZIO *z;  /* input stream */
  Mbuffer *buff;  /* buffer for tokens */
  Table *h;  /* to avoid collection/reuse strings */
  struct Dyndata *dyd;  /* dynamic structures used by the parser */
  TString *source;  /* current source name */
  TString *envn;  /* environment variable name */
  char decpoint;  /* locale decimal point */
} LexState;


LUAI_FUNC void luaX_init (lua_State *L);
LUAI_FUNC void luaX_setinput (lua_State *L, LexState *ls, ZIO *z,
                              TString *source, int firstchar);
LUAI_FUNC TString *luaX_newstring (LexState *ls, const char *str, size_t l);
LUAI_FUNC void luaX_next (LexState *ls);
LUAI_FUNC int luaX_lookahead (LexState *ls);
LUAI_FUNC l_noret luaX_syntaxerror (LexState *ls, const char *s);
LUAI_FUNC const char *luaX_token2str (LexState *ls, int token);
```

最后是这个 LexState 词法状态机，看样子是 LL(1) 文法。

这里得不到更多东西了。


## 3

嗯 开始 llex.c 文件

```C
/* ORDER RESERVED */
static const char *const luaX_tokens [] = {
    "and", "break", "do", "else", "elseif",
    "end", "false", "for", "function", "goto", "if",
    "in", "local", "nil", "not", "or", "repeat",
    "return", "then", "true", "until", "while",
    "//", "..", "...", "==", ">=", "<=", "~=",
    "<<", ">>", "::", "<eof>",
    "<number>", "<integer>", "<name>", "<string>"
};
```

首先是一波保留字的宏

说实话看到最后几个我挺惊奇的，然后就拿去解释器去试，最后发现果然是占位置用的。


```C
#define next(ls) (ls->current = zgetc(ls->z))
#define currIsNewline(ls)	(ls->current == '\n' || ls->current == '\r')
#define save_and_next(ls) (save(ls, ls->current), next(ls))
static l_noret lexerror (LexState *ls, const char *msg, int token);
```

隔了很长一段时间没更新，这期间尝试了一个正则引擎的实现，基本上搞定了python的sre的所有语法，

但是经过测试，觉得性能比较差，于是继续看一波代码学习一下。

经过一次实践，我也能够完全理解 lua lexer 的设计思路了。

lua 的 lexer 和我做的有很大不同，我在完全读取文本之后才生成了token的列表，然后将全部的 token 连带信息传给 parser。

而 lua 并未保存 lexer 的结果。

```C
static int llex (LexState *ls, SemInfo *seminfo);
```

这个函数负责读取一个 token，seminfo 用来保存 token 对应的真实值。

```C

typedef union {
  lua_Number r;
  lua_Integer i;
  TString *ts;
} SemInfo;  /* semantics information */
```

例如 TK_INT 或者 TK_FLT，就可以在 seminfo1 中保存对应的真实值。

而我在做正则引擎的时候，用了几个辅助链表来保存例如组名，组索引之类的值，这确实是一个非常好的设计。

那么细看这个文件也没什么意义了，我们前往下一节。
